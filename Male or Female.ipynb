{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a ='Training'\n",
    "b='val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1019 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(a, target_size=(224, 224), batch_size=32, class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1004 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(b, target_size=(224, 224), batch_size=32, class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.6232\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63048, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Talha Fareedi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 162s 5s/step - loss: 0.7280 - accuracy: 0.6232 - val_loss: 0.6507 - val_accuracy: 0.6305\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.7370\n",
      "Epoch 2: val_accuracy improved from 0.63048 to 0.73008, saving model to best_model.h5\n",
      "32/32 [==============================] - 154s 5s/step - loss: 0.5498 - accuracy: 0.7370 - val_loss: 0.5380 - val_accuracy: 0.7301\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.7870\n",
      "Epoch 3: val_accuracy improved from 0.73008 to 0.85657, saving model to best_model.h5\n",
      "32/32 [==============================] - 144s 5s/step - loss: 0.4554 - accuracy: 0.7870 - val_loss: 0.3648 - val_accuracy: 0.8566\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.4049 - accuracy: 0.8204\n",
      "Epoch 4: val_accuracy improved from 0.85657 to 0.87351, saving model to best_model.h5\n",
      "32/32 [==============================] - 149s 5s/step - loss: 0.4049 - accuracy: 0.8204 - val_loss: 0.3294 - val_accuracy: 0.8735\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3930 - accuracy: 0.8381\n",
      "Epoch 5: val_accuracy improved from 0.87351 to 0.89044, saving model to best_model.h5\n",
      "32/32 [==============================] - 143s 4s/step - loss: 0.3930 - accuracy: 0.8381 - val_loss: 0.2727 - val_accuracy: 0.8904\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.8518\n",
      "Epoch 6: val_accuracy did not improve from 0.89044\n",
      "32/32 [==============================] - 155s 5s/step - loss: 0.3621 - accuracy: 0.8518 - val_loss: 0.2885 - val_accuracy: 0.8884\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.8822\n",
      "Epoch 7: val_accuracy did not improve from 0.89044\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2867 - accuracy: 0.8822 - val_loss: 0.2570 - val_accuracy: 0.8855\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.8832\n",
      "Epoch 8: val_accuracy did not improve from 0.89044\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.3053 - accuracy: 0.8832 - val_loss: 0.5043 - val_accuracy: 0.7898\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.8842\n",
      "Epoch 9: val_accuracy improved from 0.89044 to 0.90538, saving model to best_model.h5\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2873 - accuracy: 0.8842 - val_loss: 0.2238 - val_accuracy: 0.9054\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.8999\n",
      "Epoch 10: val_accuracy did not improve from 0.90538\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2690 - accuracy: 0.8999 - val_loss: 0.2951 - val_accuracy: 0.8735\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2351 - accuracy: 0.9048\n",
      "Epoch 11: val_accuracy did not improve from 0.90538\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2351 - accuracy: 0.9048 - val_loss: 0.2852 - val_accuracy: 0.8805\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.8970\n",
      "Epoch 12: val_accuracy did not improve from 0.90538\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2432 - accuracy: 0.8970 - val_loss: 0.2450 - val_accuracy: 0.8974\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2371 - accuracy: 0.9078\n",
      "Epoch 13: val_accuracy did not improve from 0.90538\n",
      "32/32 [==============================] - 144s 4s/step - loss: 0.2371 - accuracy: 0.9078 - val_loss: 0.3059 - val_accuracy: 0.8725\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.9028\n",
      "Epoch 14: val_accuracy did not improve from 0.90538\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2283 - accuracy: 0.9028 - val_loss: 0.2472 - val_accuracy: 0.9014\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2059 - accuracy: 0.9127\n",
      "Epoch 15: val_accuracy did not improve from 0.90538\n",
      "32/32 [==============================] - 143s 4s/step - loss: 0.2059 - accuracy: 0.9127 - val_loss: 0.3008 - val_accuracy: 0.8775\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.9225\n",
      "Epoch 16: val_accuracy did not improve from 0.90538\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.1996 - accuracy: 0.9225 - val_loss: 0.3221 - val_accuracy: 0.8685\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.9195\n",
      "Epoch 17: val_accuracy improved from 0.90538 to 0.91633, saving model to best_model.h5\n",
      "32/32 [==============================] - 145s 5s/step - loss: 0.2190 - accuracy: 0.9195 - val_loss: 0.2338 - val_accuracy: 0.9163\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.9156\n",
      "Epoch 18: val_accuracy did not improve from 0.91633\n",
      "32/32 [==============================] - 146s 5s/step - loss: 0.1932 - accuracy: 0.9156 - val_loss: 0.4069 - val_accuracy: 0.8625\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9274\n",
      "Epoch 19: val_accuracy did not improve from 0.91633\n",
      "32/32 [==============================] - 146s 5s/step - loss: 0.1770 - accuracy: 0.9274 - val_loss: 0.2576 - val_accuracy: 0.8974\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.9274\n",
      "Epoch 20: val_accuracy did not improve from 0.91633\n",
      "32/32 [==============================] - 147s 5s/step - loss: 0.1834 - accuracy: 0.9274 - val_loss: 0.2593 - val_accuracy: 0.9004\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=20, validation_data=validation_generator, callbacks=[checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('path.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "img_path = 'Talha.jpg'  # Replace with the path to your test image\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(img_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class = \"male\" if predictions[0][0] > 0.5 else \"female\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: male\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
